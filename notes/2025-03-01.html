<!DOCTYPE html><html lang="en"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" /><link rel="stylesheet" href="../styles/style.css" /><title>Turning lambda calculus into a minimal programming language</title></head><body><p><a href="..#notes">Notes</a><br />2025/03/01</p><h1>Turning lambda calculus into a minimal programming language</h1><p><a href="https://en.wikipedia.org/wiki/Lambda_calculus">Lambda calculus</a> is <a href="https://en.wikipedia.org/wiki/Turing_completeness">Turing-complete</a>, but stuck in the <a href="https://en.wikipedia.org/wiki/Turing_tarpit">Turing tarpit</a>: "Everything is possible, but nothing of interest is easy." What would it take to turn lambda calculus into a language that retains the minimalism of the calculus, but can be used for practical programs, such as a parser for a simple language or a static site generator?</p><p>Let's add a few constructs that might be trivial, but show how the lambda calculus can be evolved into something that feels quite similar to modern languages. Enriching a calculus step by step allows us to think about and sharpen some of the <em>concepts</em> we use in programming, which are hard to see from within the uniform view of a Turing tarpit, where everything looks like a function. So, let's dive into the tarpit and slowly crawl back out again!</p><h2>Pure lambda calculus</h2><p>Lambda calculus uses only three constructs. A term t can be:</p><ul><li>a variable (which resolves to another term) such as <code>x</code> or <code>y</code>,</li><li>an abstraction (a single-argument function that returns a term) such as <code>(λx.y)</code> (which binds the argument to the variable <code>x</code> and returns <code>y</code>),</li><li>or an application (which applies a function to an argument) such as <code>(f x)</code> (which applies the term <code>x</code> to the function <code>f</code>).</li></ul><p>A bit more formally, as a <a href="https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form">BNF grammar</a>:</p><pre><code>t = x                  // variable
  | &quot;(λ&quot; var &quot;.&quot; t &quot;)&quot; // abstraction
  | &quot;(&quot; t t &quot;)&quot;        // application
</code></pre><h2>A bit of syntax and sugar</h2><p>Let's turn the calculus into something that can be used for practical programs. The first change is purely cosmetic, by using a more familiar notation for abstractions and applications: Instead of <code>(λx.y)</code>, let's use the JavaScript-inspired syntax <code>x => y</code>. Similarly, instead of <code>(f x)</code>, let's write <code>f(x)</code>, leading to the following grammar:</p><pre><code>t = var         // variable
  | var &quot;=&gt;&quot; t  // abstraction
  | t &quot;(&quot; t &quot;)&quot; // application
</code></pre><p>Without parentheses around abstractions, applications of abstractions can become ambiguous: Is <code>x => y(z)</code> meant to be a function of <code>x</code> that returns <code>y(z)</code> or the function <code>x => y</code> applied to the argument <code>z</code>? To resolve this ambiguity, let's stick with the precedence used in most programming languages and interpret <code>x => y(z)</code> as a function that returns <code>y(z)</code> and require parentheses for the other case, <code>(x => y)(z)</code>.</p><p>While we're at it, let's add a little bit of syntactic sugar. Instead of writing <code>f(x)(y)(z)</code>, we will write <code>f(x, y, z)</code>. This is merely sugar, there are no multi-argument functions in our extended calculus (because <a href="https://en.wikipedia.org/wiki/Currying">currying is sufficient</a>), we just use a more familiar function call syntax.</p><p>We will also add <a href="https://en.wikipedia.org/wiki/Let_expression">let expressions</a> of the form <code>let ... = ... ...</code> as sugar, so that...</p><pre><code>let y = f(x)
g(y, y)
</code></pre><p>...is desugared to...</p><pre><code>(y =&gt; g(y, y))(f(x))
</code></pre><p>...This allows us to stick to a more familiar flow of reading, where the definitions are introduced before they are used. (Notice how <code>f(x)</code> and <code>g(y, y)</code> are only separated by whitespace. To keep everything indentation-insensitive, the parentheses of application arguments need to start immediately after the caller, without any space between them, so that expressions like <code>let x = f(x => x)    (...)</code> can be distinguished from <code>let x = f    (x => x)(...)</code>.)</p><p>We will treat all syntactic sugar as a <em>two-way transformation</em>, meaning that it will not only be desugared into expressions during parsing, but returned expressions are also automatically re-sugared, so that for example <code>f(x)(y)</code> is <em>always</em> printed as <code>f(x, y)</code> and <code>(x => y)(z)</code> is <em>always</em> printed as <code>let x = z y</code>. Always re-sugaring expression keeps pretty-printing simple and ensures that we only adopt a tiny bit of syntactic sugar which is guaranteed to be generally applicable, not just in a case-by-case fashion.</p><h2>Data structures</h2><p>Data structures and values such as true, false, numbers and lists can be encoded in lambda calculus by using functions. <a href="https://en.wikipedia.org/wiki/Church_encoding">Church encoding</a> is probably the most well-known example of such an encoding. The boolean value true is encoded as <code>x => y => z</code> (in other words as the function returning the first of its two arguments), false is encoded as <code>x => y => y</code> (the function returning the second of its two arguments). Instead of requiring an if-then-else construct, these values <em>are</em> already a sort of if-then-else, because they are directly applied to the then/else values: Instead of writing "if true then p else q" we can just write <code>(x => y => x)(p, q)</code> and get back <code>p</code>.</p><p>The encoding for numbers is slightly more complicated and the details don't matter here, but 0 becomes <code>f => x => x</code>, 1 becomes <code>f => x => f(x)</code>, 2 becomes <code>f => x => f(f(x))</code> and so on. Notice how false and 0 are encoded as the same function in lambda calculus, in both cases returning the second argument.</p><p>Such an encoding is quite elegant, but problematic if we want to use our calculus for actual programming:</p><ul><li>Whenever we work with return values, we have to mentally translate their encoded form back into what they mean. Quick, is <code>f => x => f(f(f(f(f(x)))))</code> the encoding of 4, 5 or 6?</li><li>Multiple distinct data structures can have the same encoding, such as 0 and false. This might be fine in this case (after all, many languages treat 0 as falsy), but makes it easy to confuse different data types.</li><li>Instead of functions operating on data, lambda calculus turns this around by forcing us to encode data in such a way that data can operate on functions, because values are functions!</li></ul><p>Let's instead add two constructs to our calculus, one to construct data and one to break data apart again. To construct data, we use tags (also called symbols or atoms in Lisp / Elixir / Ruby), which are distinguished from variables by using uppercase names. <code>Foo</code> is a tag that just stands for itself and is not resolved to anything else. To construct more complex data structures such as <a href="https://en.wikipedia.org/wiki/Cons">lists</a>, we use the existing application construct and apply values to a tag (using the existing sugar for applying multiple arguments at once), for example <code>Cons(X, Nil)</code>.</p><p>To access and destructure data, we use an <code>if ... is ... ... else ...</code> conditional construct, which compares a value with a pattern and returns the then-branch if the pattern matches, or the else-branch if it does not. A pattern can either be a simple tag, such as <code>Nil</code>, or a tag applied to one or more <em>distinct</em> variables, such as <code>Cons(x, y)</code> (but <code>Cons(x, x)</code> would be invalid because the variables are not distinct). Here's an example:</p><pre><code>let list = Cons(Foo, Cons(Bar, Nil))
if list is Cons(x, xs)
  xs
else
  Nil
</code></pre><p>Since <code>list</code> matches the pattern <code>Cons(x, xs)</code>, the expression will return the then-branch, with x bound to <code>Foo</code> and xs bound to <code>Cons(Bar, Nil)</code>, thus returning <code>Cons(Bar, Nil)</code>.</p><p>This combination of tags and conditionals allow us to stick to the familiar style of programming with algebraic data types and pattern matching, but is much more minimal: We simply construct data structures (without needing to declare data types first), and patterns can only be a simple, consisting of a tag and a list of variables (instead of allowing full pattern matching with nested data structures and <a href="https://en.wikipedia.org/wiki/Unification_%28computer_science%29">unification</a>).</p><p>Let's update the grammar with our new constructs:</p><pre><code>t = ...
  | tag                        // tag (starts with uppercase)
  | &quot;if&quot; t &quot;is&quot; pat t &quot;else&quot; t // conditional

pat = tag
    | pat &quot;(&quot; var &quot;)&quot; // application with distinct (!) vars
</code></pre><h2>Explicit recursion</h2><p>While we take it for granted that function definitions in modern languages can refer to themselves and thus recursively call the function being defined, lambda calculus does not support direct (named) recursion and instead relies on <a href="https://en.wikipedia.org/wiki/Fixed-point_combinator">fixed-point combinators</a> such as:</p><pre><code>let fix = f =&gt; (x =&gt; f(x(x)))(x =&gt; f(x(x)))
fix(foo) // == foo(fix(foo)) == foo(foo(fix(foo))) == ...
</code></pre><p>This is quite elegant, but not very practical. Instead, we would like to be able to refer to the function being defined <em>by name</em>, without having to invoke a combinator. Let's define a construct <code>var ~> t</code> that works like abstractions, but instead of binding a variable to a single argument it will bind a variable to the expression itself:</p><pre><code>r ~&gt; Cons(Foo, r)
// == Cons(Foo, r ~&gt; Cons(Foo, r))
// == Cons(Foo, Cons(Foo, r ~&gt; Cons(Foo, r)))
// == Cons(Foo, Cons(Foo, Cons(Foo, r ~&gt; Cons(Foo, r))))
// == ...
</code></pre><p>Notice how we used recursion to define an infinite <em>value</em>, because that is the simplest case, but we can just as well use it to define a recursive function such as <a href="https://en.wikipedia.org/wiki/Map_%28higher-order_function%29">map</a>:</p><pre><code>map ~&gt; f =&gt; xs =&gt;
  if xs is Cons(x, xs)
    Cons(f(x), map(f, xs))
  else
    xs
</code></pre><p>It is often useful to define a recursive function and then bind it with the same name in a let expression, but it is annoying to have to type the same name twice. Let's add a bit of sugar for such a case, so that...</p><pre><code>loop r = x
y
</code></pre><p>...will be desugared to...</p><pre><code>let r = r ~&gt; x
y
</code></pre><p>Putting it all together, here's how we can define and apply our map function:</p><pre><code>loop map = f =&gt; xs =&gt;
  if xs is Cons(x, xs)
    Cons(f(x), map(f, xs))
  else
    xs

map(x =&gt; Foo(x), Cons(Bar, Cons(Baz, Nil)))
// == Cons(Foo(Bar), Cons(Foo(Baz), Nil))
</code></pre><p>Let's update the grammar with our recursion construct:</p><pre><code>t = ...
  | var &quot;~&gt;&quot; t // recursion
</code></pre><h2>Putting it together</h2><p>This brings the total number of constructs up to 6: The original 3 lambda calculus constructs (variables, abstractions, applications), 2 more for data structures and 1 for recursion:</p><pre><code>t = var                        // variable
  | var &quot;=&gt;&quot; t                 // abstraction
  | t &quot;(&quot; t &quot;)&quot;                // application
  | tag                        // tag
  | &quot;if&quot; t &quot;is&quot; pat t &quot;else&quot; t // conditional
  | var &quot;~&gt;&quot; t                 // recursion
</code></pre><p>This is again ignoring ambiguity and precedence issues introduced by missing parentheses. We can resolve any ambiguity by observing that three constructs can end with a term t (abstractions, recursions and conditionals) and that only these constructs need to be wrapped in parentheses when they appear as the left term of an application:</p><pre><code>t = t&apos;  // might need to be wrapped in parentheses
  | t&apos;&apos; // never need parentheses

t&apos; = var &quot;=&gt;&quot; t
   | var &quot;~&gt;&quot; t
   | &quot;if&quot; t &quot;is&quot; pat t &quot;else&quot; t

t&apos;&apos; = var
    | tag
    | &quot;(&quot; t&apos; &quot;)(&quot; t &quot;)&quot;
    | t&apos;&apos; &quot;(&quot; t &quot;)&quot;
</code></pre><h2>A separation of concepts</h2><p>Why go through all the trouble of adding three new constructs and a bit of sugar to the lambda calculus? Isn't the end result pretty trivial, having exactly the same expressive power as lambda calculus? Yes, but that's the point! All of the above extensions are mathematically trivial and have been proposed before (the resulting calculus is quite similar to <a href="https://en.wikipedia.org/wiki/Programming_Computable_Functions">Plotkin's PCF</a>, for example), but enriching a calculus in such a way can clarify some of the <em>concepts</em> we use in everyday programming.</p><p>Viewed from within the Turing tarpit of the lambda calculus, there is no difference between functions and data, they are the same concept. This is mathematically elegant, but philosophically poor, because we lose a conceptual distinction that is quite useful in programming. (There might be some echoes of <a href="https://en.wikipedia.org/wiki/Remarks_on_the_Foundations_of_Mathematics">Wittgenstein's remarks</a> on the difference between mathematics and philosophy here.)</p><p>Same for abstraction and recursion: From the perspective of the lambda calculus there is only a single concept, but in everyday programming it is extremely useful to distinguish between recursive and non-recursive functions. For example, we know that non-recursive functions that only call other non-recursive functions must eventually terminate (in the absence of unrestricted loops).</p><p>By splitting abstraction and recursion into distinct concepts, we can start to treat them differently: Perhaps we want to use <a href="https://en.wikipedia.org/wiki/Evaluation_strategy#Call_by_value">call-by-value</a> evaluation for non-recursive functions, but evaluate recursive data and functions <a href="https://en.wikipedia.org/wiki/Evaluation_strategy#Call_by_need">lazily</a>? (This is similar to how <a href="https://en.wikipedia.org/wiki/Call-by-push-value">Call-by-push-value</a> distinguishes <em>values</em> from <em>computations</em>.)</p><h2>Going further</h2><p>What else can be added to the calculus without sacrificing its minimalism?</p><ul><li>The sugar for applying multiple arguments could be extended to abstractions, so that <code>(x, y) => z</code> desugars to <code>x => y => z</code>.</li><li>Nested lists such as <code>Cons(X, Cons(Y, Cons(Z, Nil)))</code> are cumbersome. It might make sense to add sugar for nested applications of tags, such as <code>Cons [X, Y, Z]</code> for <code>Cons(X, Cons(Y, Cons(Z, Cons)))</code>, treating a non-applied Cons as Nil?</li><li>While there's a separate recursion construct, nothing is stopping us from ignoring it and using combinators. It would be interesting to check statically that normal abstractions are only used non-recursively without bringing in a full type system. Such a check would need to be purely syntactic to avoid being <a href="https://en.wikipedia.org/wiki/Undecidable_problem">undecidable</a>.</li><li>The calculus currently has no way to interface with the outside world. Adding <a href="https://en.wikipedia.org/wiki/Effect_system">effect handlers</a> or <a href="https://en.wikipedia.org/wiki/Delimited_continuation">delimited continuations</a> could solve this.</li><li>The calculus is defined in terms of named variables, but becomes simpler if <a href="https://en.wikipedia.org/wiki/De_Bruijn_index">de Bruijn indices</a> are used. The restriction that variables in a pattern need to be distinct falls away, instead with de Bruijn indices a pattern would only need to specify how many variables to bind.</li><li>The conditional is the only control structure, abstractions and recursions are the only binding structures. Practical programs might benefit from user-defined control or binding structures. Lisp-like macros are an obvious answer, but perhaps it makes sense to explore restricted options?</li></ul><p>More on these in future notes.</p><footer>Want to become a better programmer? <a href="https://www.recurse.com/scout/click?t=764048f99cede394c1905c64e1545a5d">Join the Recurse Center!</a></footer></body></html>