<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Turning Lambda Calculus Into a Minimal Programming Language</title>
    <link rel="stylesheet" href="../styles/style.css" />
  </head>
  <body>
    <p>
      <a href="../index.html">Notes</a><br /><time datetime="2025-03-01"
        >2025/03/01</time
      >
    </p>
    <h1>Turning Lambda Calculus Into a Minimal Programming Language</h1>
    <p>
      <a href="https://en.wikipedia.org/wiki/Lambda_calculus"
        >Lambda calculus</a
      >
      is
      <a href="https://en.wikipedia.org/wiki/Turing_completeness"
        >Turing-complete</a
      >, but stuck in the
      <a href="https://en.wikipedia.org/wiki/Turing_tarpit">Turing tarpit</a>:
      “Everything is possible, but nothing of interest is easy.” What would it
      take to turn lambda calculus into a language that retains the minimalism
      of the calculus, but can be used for practical programs, such as a parser
      for a simple language or a static site generator?
    </p>
    <p>
      Let's add a few constructs that might be trivial, but show how the lambda
      calculus can be evolved into something that feels quite similar to modern
      languages. Enriching a calculus step by step allows us to think about and
      sharpen some of the <em>concepts</em> we use in programming, which are
      hard to see from within the uniform view of a Turing tarpit, where
      everything looks like a function. So, let's dive into the tarpit and
      slowly crawl back out again!
    </p>
    <p>
      (You can see the results of this experiment on
      <a
        href="https://github.com/fkettelhoit/vorpal/tree/lambda-calculus-as-minimal-pl"
        >Github</a
      >.)
    </p>
    <h1>Pure Lambda Calculus</h1>
    <p>Lambda calculus uses only three constructs. A term t can be:</p>
    <ul>
      <li>a variable (which resolves to another term) such as “x” or “y”,</li>
      <li>
        an abstraction (a single-argument function that returns a term) such as
        “(λx.y)” (which binds the argument to the variable “x” and returns “y”),
      </li>
      <li>
        or an application (which applies a function to an argument) such as “(f
        x)” (which applies the term “x” to the function “f”).
      </li>
    </ul>
    <p>
      A bit more formally, as a
      <a href="https://en.wikipedia.org/wiki/Backus%E2%80%93Naur_form"
        >BNF grammar</a
      >:
    </p>
    <pre><code>t = x                  // variable
  | "(λ" var "." t ")" // abstraction
  | "(" t t ")"        // application</code></pre>
    <h1>A Bit of Syntax and Sugar</h1>
    <p>
      Let's turn the calculus into something that can be used for practical
      programs. The first change is purely cosmetic, by using a more familiar
      notation for abstractions and applications: Instead of “(λx.y)”, let's use
      the JavaScript-inspired syntax “x => y”. Similarly, instead of “(f x)”,
      let's write “f(x)”, leading to the following grammar:
    </p>
    <pre><code>t = var         // variable
  | var "=>" t  // abstraction
  | t "(" t ")" // application</code></pre>
    <p>
      Without parentheses around abstractions, applications of abstractions can
      become ambiguous: Is “x => y(z)” meant to be a function of “x” that
      returns “y(z)” or the function “x => y” applied to the argument “z”? To
      resolve this ambiguity, let's stick with the precedence used in most
      programming languages and interpret “x => y(z)” as a function that returns
      “y(z)” and require parentheses for the other case, “(x => y)(z)”.
    </p>
    <p>
      While we're at it, let's add a little bit of syntactic sugar. Instead of
      writing “f(x)(y)(z)”, we will write “f(x, y, z)”. This is merely sugar,
      there are no multi-argument functions in our extended calculus (because
      <a href="https://en.wikipedia.org/wiki/Currying">currying is sufficient</a
      >), we just use a more familiar function call syntax.
    </p>
    <p>
      We will also add
      <a href="https://en.wikipedia.org/wiki/Let_expression">let expressions</a>
      of the form “let ... = ... ...” as sugar, so that...
    </p>
    <pre><code>let y = f(x)
g(y, y)</code></pre>
    <p>...is desugared as...</p>
    <pre><code>(y => g(y, y))(f(x))</code></pre>
    <p>
      This allows us to stick to a more familar flow of reading, where the
      definitions are introduced before they are used. (Notice how “f(x)” and
      “g(y, y)” are only separated by whitespace. To keep everything
      indentation-insensitive, the parentheses of application arguments need to
      start immediately after the caller, without any space between them, so
      that expressions like “let x = f(x => x)&nbsp;&nbsp;&nbsp;(...)” can be
      distinguished from “let x = f&nbsp;&nbsp;&nbsp;(x => x)(...)”.)
    </p>
    <p>
      We will treat all syntactic sugar as a <em>two-way transformation</em>,
      meaning that it will not only be desugared into expressions during
      parsing, but returned expressions are also automatically “re-sugared”, so
      that for example “f(x)(y)” is <em>always</em> printed as “f(x, y)” and “(x
      => y)(z)” is <em>always</em> printed as “let x = z y”. Always re-sugaring
      expression keeps pretty-printing simple and ensures that we only adopt a
      tiny bit of syntatic sugar which is guaranteed to be generally applicable,
      not just in a case-by-case fashion.
    </p>
    <h1>Data Structures</h1>
    <p>
      Data structures and values such as true, false, numbers and lists can be
      encoded in lambda calculus by using functions.
      <a href="https://en.wikipedia.org/wiki/Church_encoding"
        >Church encoding</a
      >
      is probably the most well-known example of such an encoding. The boolean
      value true is encoded as “x => y => z” (in other words as the function
      returning the first of its two arguments), false is encoded as “x => y =>
      y” (the function returning the second of its two arguments). Instead of
      requiring an if-then-else construct, these values <em>are</em> already a
      sort of if-then-else, because they are directly applied to the then/else
      values: Instead of writing “if true then p else q” we can just write “(x
      => y => x)(p, q)” and get back “p”.
    </p>
    <p>
      The encoding for numbers is slightly more complicated and the details
      don't matter here, but 0 becomes “f => x => x”, 1 becomes “f => x =>
      f(x)”, 2 becomes “f => x => f(f(x))” and so on. Notice how false and 0 are
      encoded as the same function in lambda calculus, in both cases returning
      the second argument.
    </p>
    <p>
      Such an encoding is quite elegant, but problematic if we want to use our
      calculus for actual programming:
    </p>
    <ul>
      <li>
        Whenever we work with return “values”, we have to mentally translate
        their encoded form back into what they “mean”. Quick, is “f => x =>
        f(f(f(f(f(x)))))” the encoding of 4, 5 or 6?
      </li>
      <li>
        Multiple distinct data structures can have the same encoding, such as 0
        and false. This might be fine in this case (after all, many languages
        treat 0 as falsy), but makes it easy to confuse different data types.
      </li>
      <li>
        Instead of functions operating on data, lambda calculus turns this
        around by forcing us to encode data in such a way that data can operate
        on functions, because values are functions!
      </li>
    </ul>
    <p>
      Let's instead add two constructs to our calculus, one to construct data
      and one to break data apart again. To construct data, we use “tags” (also
      called “symbols” or “atoms” in Lisp / Elixir / Ruby), which are
      distinguished from variables by using uppercase names. “Foo” is a tag that
      just stands for itself and is not resolved to anything else. To construct
      more complex data structures such as
      <a href="https://en.wikipedia.org/wiki/Cons">lists</a>, we use the
      existing application construct and apply values to a tag (using the
      existing sugar for applying multiple arguments at once), for example
      “Cons(X, Nil)”.
    </p>
    <p>
      To access and destructure data, we use an “if ... is ... ... else ...”
      conditional construct, which compares a value with a pattern and returns
      the then-branch if the pattern matches, or the else-branch if it does not.
      A pattern can either be a simple tag, such as “Nil”, or a tag applied to
      one or more <em>distinct</em> variables, such as “Cons(x, y)” (but
      “Cons(x, x)” would be invalid because the variables are not distinct).
      Here's an example:
    </p>
    <pre><code>let list = Cons(Foo, Cons(Bar, Nil))
if list is Cons(x, xs)
  xs
else
  Nil</code></pre>
    <p>
      Since “list” matches the pattern “Cons(x, xs)”, the expression will return
      the then-branch, with x bound to “Foo” and xs bound to “Cons(Bar, Nil)”,
      thus returning “Cons(Bar, Nil)”.
    </p>
    <p>
      This combination of tags and conditionals allow us to stick to the
      familiar style of programming with algebraic data types and pattern
      matching, but is much more minimal: We simply construct data structures
      (without needing to declare data types first), and patterns can only be a
      simple, consisting of a tag and a list of variables (instead of allowing
      full pattern matching with nested data structures and
      <a href="https://en.wikipedia.org/wiki/Unification_(computer_science)"
        >unification</a
      >).
    </p>
    <p>Let's update the grammar with our new constructs:</p>
    <pre><code>t = ...
  | tag                        // tag (starts with uppercase)
  | "if" t "is" pat t "else" t // conditional

pat = tag
    | pat "(" var ")" // application with distinct (!) vars</code></pre>
    <h1>Explicit Recursion</h1>
    <p>
      While we take it for granted that function definitions in modern languages
      can refer to themselves and thus recursively call the function being
      defined, lambda calculus does not support direct (named) recursion and
      instead relies on
      <a href="https://en.wikipedia.org/wiki/Fixed-point_combinator"
        >fixed-point combinators</a
      >
      such as:
    </p>
    <pre><code>let fix = f => (x => f(x(x)))(x => f(x(x)))
fix(foo) // == foo(fix(foo)) == foo(foo(fix(foo))) == ...</code></pre>
    <p>
      This is quite elegant, but not very practical. Instead, we would like to
      be able to refer to the function being defined <em>by name</em>, without
      having to invoke a combinator. Let's define a construct “var ~> t“ that
      works like abstractions, but instead of binding a variable to a single
      argument it will bind a variable to the expression itself:
    </p>
    <pre><code>r ~> Cons(Foo, r)
// == Cons(Foo, r ~> Cons(Foo, r))
// == Cons(Foo, Cons(Foo, r ~> Cons(Foo, r)))
// == Cons(Foo, Cons(Foo, Cons(Foo, r ~> Cons(Foo, r))))
// == ...</code></pre>
    <p>
      Notice how we used recursion to define an infinite <em>value</em>, because
      that is the simplest case, but we can just as well use it to define a
      recursive function such as
      <a href="https://en.wikipedia.org/wiki/Map_(higher-order_function)">map</a
      >:
    </p>
    <pre><code>map ~> f => xs =>
  if xs is Cons(x, xs)
    Cons(f(x), map(f, xs))
  else
    xs</code></pre>
    <p>
      It is often useful to define a recursive function and then bind it with
      the same name in a let expression, but it is annoying to have to type the
      same name twice. Let's add a bit of sugar for such a case, so that...
    </p>
    <pre><code>loop r = x
y</code></pre>
    <p>...will be desugared as...</p>
    <pre><code>let r = r ~> x
y</code></pre>
    <p>
      Putting it all together, here's how we can define and apply our map
      function:
    </p>
    <pre><code>loop map = f => xs =>
  if xs is Cons(x, xs)
    Cons(f(x), map(f, xs))
  else
    xs

map(x => Foo(x), Cons(Bar, Cons(Baz, Nil)))
// == Cons(Foo(Bar), Cons(Foo(Baz), Nil))</code></pre>
    <p>Let's update the grammar with our recursion construct:</p>
    <pre><code>t = ...
  | var "~>" t // recursion</code></pre>
    <h1>Putting it Together</h1>
    <p>
      This brings the total number of constructs up to 6: The original 3 lambda
      calculus constructs (variables, abstractions, applications), 2 more for
      data structures and 1 for recursion:
    </p>
    <pre><code>t = var                        // variable
  | var "=>" t                 // abstraction
  | t "(" t ")"                // application
  | tag                        // tag
  | "if" t "is" pat t "else" t // conditional
  | var "~>" t                 // recursion</code></pre>
    <p>
      This is again ignoring ambiguity and precedence issues introduced by
      missing parentheses. We can resolve any ambiguity by observing that three
      constructs can end with a term t (abstractions, recursions and
      conditionals) and that only these constructs need to be wrapped in
      parentheses when they appear as the left term of an application:
    </p>
    <pre><code>t = t'  // might need to be wrapped in parentheses
  | t'' // never need parentheses

t' = var "=>" t
   | var "~>" t
   | "if" t "is" pat t "else" t

t'' = var
    | tag
    | "(" t' ")(" t ")"
    | t'' "(" t ")"</code></pre>
    <p>
      The Rust code for the parser, pretty-printer and evaluator is on
      <a
        href="https://github.com/fkettelhoit/vorpal/tree/lambda-calculus-as-minimal-pl"
        >Github</a
      >.
    </p>
    <h1>A Separation of Concepts</h1>
    <p>
      Why go through all the trouble of adding three new constructs and a bit of
      sugar to the lambda calculus? Isn't the end result pretty trivial, having
      exactly the same expressive power as lambda calculus? Yes, but that's the
      point! All of the above extensions are mathematically trivial and have
      been proposed before (the resulting calculus is quite similar to
      <a href="https://en.wikipedia.org/wiki/Programming_Computable_Functions"
        >Plotkin's PCF</a
      >, for example), but enriching a calculus in such a way can clarify some
      of the <em>concepts</em> we use in everyday programming.
    </p>
    <p>
      Viewed from within the Turing tarpit of the lambda calculus, there is no
      difference between functions and data, they are the same concept. This is
      mathematically elegant, but philosophically poor, because we lose a
      conceptual distinction that is quite useful in programming. (There might
      be some echoes of
      <a
        href="https://en.wikipedia.org/wiki/Remarks_on_the_Foundations_of_Mathematics"
        >Wittgenstein's remarks</a
      >
      on the difference between mathematics and philosophy here.)
    </p>
    <p>
      Same for abstraction and recursion: From the perspective of the lambda
      calculus there is only a single concept, but in everyday programming it is
      extremely useful to distinguish between recursive and non-recursive
      functions. For example, we know that non-recursive functions that only
      call other non-recursive functions must eventually terminate (in the
      absence of unrestricted loops).
    </p>
    <p>
      By splitting abstraction and recursion into distinct concepts, we can
      start to treat them differently: Perhaps we want to use
      <a href="https://en.wikipedia.org/wiki/Evaluation_strategy#Call_by_value"
        >call-by-value</a
      >
      evaluation for non-recursive functions, but evaluate recursive data and
      functions
      <a href="https://en.wikipedia.org/wiki/Evaluation_strategy#Call_by_need"
        >lazily</a
      >? (This is similar to how
      <a href="https://en.wikipedia.org/wiki/Call-by-push-value"
        >Call-by-push-value</a
      >
      distinguishes <em>values</em> from <em>computations</em>.)
    </p>
    <h1>Going Further</h1>
    <p>
      What else can be added to the calculus without sacrificing its minimalism?
    </p>
    <ul>
      <li>
        The sugar for applying multiple arguments could be extended to
        abstractions, so that “(x, y) => z” desugares as “x => y => z”.
      </li>
      <li>
        Nested lists such as “Cons(X, Cons(Y, Cons(Z, Nil)))” are cumbersome. It
        might make sense to add sugar for nested applications of tags, such as
        “Cons [X, Y, Z]” for “Cons(X, Cons(Y, Cons(Z, Cons)))”, treating a
        non-applied Cons as Nil?
      </li>
      <li>
        While there's a separate recursion construct, nothing is stopping us
        from ignoring it and using combinators. It would be interesting to check
        statically that normal abstractions are only used non-recursively
        without bringing in a full type system. Such a check would need to be
        purely syntactic to avoid being
        <a href="https://en.wikipedia.org/wiki/Undecidable_problem"
          >undecidable</a
        >.
      </li>
      <li>
        The calculus currently has no way to interface with the outside world.
        Adding
        <a href="https://en.wikipedia.org/wiki/Effect_system"
          >effect handlers</a
        >
        or
        <a href="https://en.wikipedia.org/wiki/Delimited_continuation"
          >delimited continuations</a
        >
        could solve this.
      </li>
      <li>
        The calculus is defined in terms of named variables, but becomes simpler
        if
        <a href="https://en.wikipedia.org/wiki/De_Bruijn_index"
          >de Bruijn indices</a
        >
        are used. The restriction that variables in a pattern need to be
        distinct falls away, instead with de Bruijn indices a pattern would only
        need to specify how many variables to bind.
      </li>
      <li>
        The conditional is the only control structure, abstractions and
        recursions are the only binding structures. Practical programs might
        benefit from user-defined control or binding structures. Lisp-like
        macros are an obvious answer, but perhaps it makes sense to explore
        restricted options?
      </li>
    </ul>
  </body>
</html>
