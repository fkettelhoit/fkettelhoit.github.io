<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <title>Custom Bindings Constructs Without Macros</title>
    <link rel="stylesheet" href="../styles/style.css" />
  </head>
  <body>
    <p>
      <a href="../index.html">Notes</a><br /><time datetime="2025-03-16"
        >2025/03/16</time
      >
    </p>
    <h1>Custom Binding Constructs Without Macros, Part 1: Explicit Bindings</h1>
    <p>
      Programming languages face a tension between the ability to extend them
      <em>dynamically</em> and the ability to reason about them
      <em>statically.</em> We take it for granted that constructs that
      <em>bind variables</em>, such as function definitions or pattern matching,
      are a fixed part of a language's core syntax, unless we go for
      <a
        href="https://en.wikipedia.org/wiki/Lisp_(programming_language)#List_structure_of_program_code;_exploitation_by_macros_and_compilers"
        >Lisp-like macros</a
      >, which are powerful but hard to reason about.
    </p>
    <p>
      There is an unexplored middle ground, however, of allowing binding
      constructs to be defined and extended, while ensuring that all variables
      are lexically bound and that their scope can be determined statically.
      What follows is an exploration of this middle ground, while respecting a
      single guiding principle:
    </p>
    <p>
      <em
        >Every construct in the language can be redefined, there are no
        privileged language constructs. But the scope of variables remains
        immediately obvious, just by looking at the source code, without
        evaluating any functions.</em
      >
    </p>
    <p>
      The result will be a surface syntax that looks similarly dynamic to Lisp
      macros, but is fully desugared to a functional language without macros.
    </p>
    <h1>Dynamic vs. Static Syntax</h1>
    <p>
      The more a language is defined in terms of static constructs that cannot
      be redefined, the easier it is to reason about (both for humans and
      compilers), because we can be sure that certain constructs always mean the
      same thing and cannot be rebound. But the more dynamic a language is (by
      aggressively using late binding such as
      <a href="https://en.wikipedia.org/wiki/Self_(programming_language)"
        >Self</a
      >
      and
      <a href="https://en.wikipedia.org/wiki/Io_(programming_language)">Io</a>,
      or by using Lisp-like macros), the more it can be molded for a particular
      usecase that the original language designers might not have had in mind.
    </p>
    <p>
      This tension is quite visible for <em>binding constructs</em>, in other
      words constructs that involve binding one or more variables in the scope
      of a function or block. Even heavily dynamic languages usually only
      support variables to be bound by special constructs, for example
      assignment operators like “=”, in function definition or at the beginning
      of lambdas/blocks/closures.
    </p>
    <p>
      This makes it hard to define new constructs that bind variables, such as a
      pattern matching construct in a language that doesn't provide it, because
      a pattern matching construct needs to take a <em>pattern</em>, which might
      include fresh variables, and then <em>bind</em> these variables to their
      matched values in the scope of a body, but only execute the body if the
      match actually succeeds. There seem to be two different ways to deal with
      such a situation in a language:
    </p>
    <ul>
      <li>
        Just accept that binding constructs are fixed (and that language
        designers need to be lobbied to add new bindings constructs, such as a
        pattern matching construct).
      </li>
      <li>
        Use macros to operate on expressions
        <em>before they are resolved as variables</em>, effectively adding a
        meta level to the language that can decide whether to treat the “x” in
        “foo(x)” as a bound symbol, a fresh variable or something else entirely.
      </li>
    </ul>
    <p>
      Lisp macros are the best example for the second option. They are
      definitely powerful enough to add any construct we could possibly think
      of, and then some! But this power comes at a price. Let's take a look at
      the following Lisp code:
    </p>
    <pre><code>(foo (bar a b) (baz x y))</code></pre>
    <p>
      Which functions are being called here? Well, without looking at the
      context of the program we wouldn't know, because foo could be a macro, in
      which case bar and baz might not be functions, but just symbols that might
      mean whatever the macro interprets them as. This is of course why macros
      should be used sparingly: They are extremely powerful, but might make it
      harder for humans to figure out what is happening, because macros can
      obscure the structure of code.
    </p>
    <p>
      Extensive use of macros violates the
      <a href="https://www.w3.org/DesignIssues/Principles.html#PLP"
        >principle of least power</a
      >: Powerful language features can be enticing, but power isn't everything,
      or we would all be happily living in the
      <a href="./001-lambda-calculus-as-minimal-pl.html"
        >Turing tarpit of the lambda calculus</a
      >. Well-chosen restrictions and limitations help us reason more easily
      about code. Macros are powerful, but they come with almost no limitations.
    </p>
    <p>Can we do better?</p>
    <h1>Step 1: Making Bindings Explicit</h1>
    <p>
      Let's start with an observation. Most languages do not visually
      distinguish between bound variables that are <em>used</em> and fresh
      variables that are <em>bound:</em>
    </p>
    <pre><code>a + b // the variable a is being used
a = b // the variable a is being bound</code></pre>
    <p>
      In the first case, “a + b”, the variable a is looked up in the current
      scope, whereas in the second case, “a = b”, a is a fresh variable that
      will be bound in the current scope. That they play such different roles is
      not visible just by looking at the variables, nor by looking at the
      operators, because + and = both look like infix symbols. That's bad news
      if we want to allow all constructs to be definable by the user.
    </p>
    <p>
      Let's distinguish these two cases by making the different roles explicit.
      Whenever a variable is resolved in the current scope and <em>used</em>, we
      will continue to just write its name. But whenever a fresh variable is
      being bound, we prefix it with a single quote:
    </p>
    <pre><code>a + b  // the variable a is being used
'a = b // the variable a is being bound</code></pre>
    <h1>Step 2: Splitting Bindings and Blocks</h1>
    <p>
      We haven't said anything about where and for how long a variable remains
      in scope. Let's make this scope explicit by writing “{ ... }”, which
      delimits the <em>block</em> where a binding is active. A variable that is
      bound inside the block goes out of scope at the end of the block.
    </p>
    <p>
      So far, so normal. But let's depart from how bindings are defined in other
      languages by <em>splitting</em> the place where bindings are declared from
      the blocks where they are bound:
    </p>
    <pre><code>foo('x, y, { f(x) })
//  |      \______/
//  |      scope of x
//  |
//  \__ binding of x</code></pre>
    <p>
      Whenever a variable is single-quoted and appears as 'x, it will be bound
      as x in the nearest block the appears after it (technically using a
      depth-first traversal of the AST, which matches what we visually perceive
      as the nearest block).
    </p>
    <p>
      Viewed from the perspective of the block { f(x) }, we can immediately tell
      which variables are bound inside this block and which variables are
      resolved in the outer scope, just by looking at the explicit bindings to
      the left of the block (or until we encounter another block, which would
      then “consume” all the explicit bindings to the left of it). In the
      example above, we see that x is explicitly bound in { f(x) }, whereas f
      will be looked up in the outer scope.
    </p>
    <p>
      What is the value of x in the block? Well, we can't know syntactically,
      because it is up to the function foo, which receives 'x as an argument, to
      decide what value x is bound to. It could act like a “let x = y in ...”
      construct and bind x to the value y or do something else, the value is
      entirely up to the implementation of foo. But it is
      <em>statically guaranteed</em> that foo will bind x to <em>some</em> value
      and this is how the block { f(x) } gets its value for x.
    </p>
    <p>
      This is all a bit abstract, so let's look at how this might be used to
      define a pattern matching construct in a language that does not already
      provide such a construct. Let's write “Pair(x, y)” for a struct named Pair
      with two fields containing the values x and y. Matching on a value v if v
      is a pair where both fields are the same could look as follows:
    </p>
    <pre><code>match(v, Pair('x, 'x), { x })</code></pre>
    <p>
      The block { x } is statically guaranteed to receive the value of x from
      the function match, x will have that value only for as long as the block
      is active and go out of scope at the end of it.
    </p>
    <p>
      The match function is responsible for deciding how x is bound, based on
      the arguments v and Pair('x, 'x). It could bind x only if v is a Pair and
      both fields have the same value, calling the block with x bound to that
      value and returning an error value otherwise. Or it could treat the first
      'x as being shadowed by the second 'x, in which case the call would match
      every pair and return its second field. The point is: The value of x is up
      to the implementation of match, but x must be bound by the match function
      before the block is called.
    </p>
    <p>
      Under the hood, a block is simply desugared into an anonymous function,
      with the number and names of its arguments being determined statically by
      the explicit bindings that precede it. If a block is not preceded by any
      explicit bindings, it will be treated as a single argument function that
      simply ignores its argument.
    </p>
    <p>
      In a language with arrays written as “[..., ...]” and user-definable infix
      functions like “... -> ...”, a pattern matching construct could then look
      as follows:
    </p>
    <pre><code>match(x, [
  Pair('x, 'x) -> { x },
  'x           -> { ... }
])</code></pre>
    <h1>Step 3: Nesting Bindings and Blocks</h1>
    <p>
      Let's add a bit more syntactic sugar: Right now blocks always have to be
      used <em>after</em> the explicit bindings that the block is supposed to
      consume, but it makes sense to also allow blocks to consume bindings by
      <em>enclosing</em> bindings:
    </p>
    <pre><code>{
  let('x, y),
  x
}</code></pre>
    <p>
      Whenever explicit bindings are declared inside a block but not consumed
      until the end of the block, the bindings will be consumed by the enclosing
      block, as if everything that follows the call with the explicit bindings
      had been passed as a block right then. The above example will be desugared
      to “let('x, y, { f(x) })” In other words, instead of passing a block as
      the last argument of a function call, we can just use that function inside
      the block. This is especially helpful for nested bindings:
    </p>
    <pre><code>// desugars to: let('a, x, { let('b, y, { Pair(a, b) }) })
{
  let('a, x),
  let('b, y),
  Pair(a, b)
}</code></pre>
    <p>
      Right now we assume that every element in a block will be a binding
      construct that knows how to handle the block argument that is implicitly
      passed to it. But especially in a language with side effects it would be
      nice to allow block elements to not bind anything at all and just “do”
      something, like print(a).
    </p>
    <p>
      To allow this, let's decide that whenever a block element does not contain
      any explicit bindings that could be consumed by the enclosing block, the
      element will be evaluated (assuming call-by-value) as an argument to an
      anonymous function, which when called will return the rest of the block.
      (We write (x => y) for the function that takes an argument x and returns
      y, keeping in mind that this is not surface syntax, because the binding is
      not explicitly marked.)
    </p>
    <pre><code>// binding constructs
// desugar to: let('x, Foo)(x => ...)
{ let('x, Foo), ... }

// non-binding constructs, for example side effects
// desugar to: (_ => ...)(f())
{ f(), ... }</code></pre>
    <p>This makes it easy to mix binding constructs and side effects:</p>
    <pre><code>// desugars to: let('a, x, { (_ => f(a))(print(a)) })
{
  let('a, x),
  print(a),
  f(a)
}</code></pre>
    <h1>Step 4: Joining Bindings and Blocks</h1>
    <p>
      So far we have looked at how binding constructs can be <em>used,</em> but
      how can they actually be <em>defined?</em> Let's say we wanted to define
      our own let binding construct, called “def”, which can be called as
      def('x, value, { x }). How would we implement def?
    </p>
    <p>
      We already know that the second argument, value, is just a normally
      evaluated function argument. We also know that blocks are just syntactic
      sugar and get translated into anonymous functions, with the number of
      arguments determined by the bindings to its left. In the case of def('x,
      value, { x }), the block { x } is translated to the function ('x => x).
      But what about the first argument, 'x? If explicit bindings are purely
      syntactical and get desugared into a functional language without macros,
      how are explicit bindings translated?
    </p>
    <p>
      The exact representation of a binding at runtime depends on the specific
      host language, but any representation of a binding-as-value must meet a
      couple of criteria:
    </p>

    <ul>
      <li>
        A binding-as-value cannot be created at runtime by a user of the
        language, the only way to create a binding-as-value is to declare it
        explicitly using single-quoting in the syntax, ensuring that the number
        of bindings can be tracked statically.
      </li>
      <li>
        The name of a binding-as-value cannot be inspected at runtime, ensuring
        that any bindings
        <a
          href="https://en.wikipedia.org/wiki/Lambda_calculus#Alpha_equivalence"
          >can be renamed</a
        >
        in the source code without affecting any runtime behavior.
      </li>
      <li>
        A binding-as-value can be compared with another binding-as-value for
        equality, ensuring that Pair('x, 'x) can be distinguished from Pair('x,
        'y).
      </li>
    </ul>
    <p>
      Returning to the example of defining a custom let binding, our def
      function needs to check that its first argument (the binding-as-value) is
      a single binding, in which case we know it's safe to call the third
      argument (the block) as a function with a single argument.
    </p>
    <pre><code>// assuming the following built-in functions:
// `=>`, infix binding construct, for single argument functions,
// `if`, if-then-else, executes either the then-block or else-block,
// `is-binding`, returns true if its argument is a binding-as-value.
'var => {
  'v => {
    'f => {
      if(is_binding(var), { f(v) }, { Error })
    }
  }
}

// or in a more familiar notation without explicit bindings:
// (var, v, f) =>
//   if(is_binding(var), () => f(v), () => Error)</code></pre>
    <p>
      The above example used several built-in functions and thus might seem to
      beg the question, but crucially all of these functions are normal
      functions that can be redefined. They are not privileged in any way.
    </p>
    <p>
      The above implementation of a custom let binding is only a rough sketch.
      The code for steps 1 to 3 (the translation from surface syntax with
      explicit bindings to a functional calculus with normal lambdas) is on
      <a
        href="https://github.com/fkettelhoit/vorpal/tree/custom-binding-constructs-without-macros"
        >Github</a
      >.
    </p>
    <h1>Open Question: Using Bindings More Than Once</h1>
    <p>
      The current proposal assumes that explicit bindings can only be used in a
      single scope, because they get consumed by the nearest block and are not
      available in the next block. Frequently, however, it would make sense to
      bind a variable both in the block that follows and in the enclosing block.
    </p>
    <p>
      A good example is letrec, the recursive cousin of let that allows the
      value-to-be-bound to access the binding recursively:
    </p>
    <pre><code>// we'd like to define r = Cons(x, r) = Cons(x, Cons(x, r)) = ...
// not possible right now, r is only in scope in the inner block
{
  letrec('r, { Cons(x, r) }),
  head(r) // r is not in scope here anymore, was already consumed
}</code></pre>
    <p>
      How can this be solved? I see two options, neither of which seems ideal:
    </p>
    <ul>
      <li>
        Explicit bindings can be used more than once if an enclosing block is
        found synactically <em>immediately</em> above where a binding is
        consumed in the AST. This would make the above example “just work”, but
        feels like too much magic.
      </li>
      <li>
        There is a way to explictly mark bindings as being used more than once,
        for example ''x to signal that the binding can be consumed twice,
        whereas '''x can be consumed three times.
      </li>
    </ul>
    <p>
      Either way, more exploration is needed. Nevertheless, explicit bindings
      and user-defined binding constructs seem to be an interesting direction
      that I haven't encountered in any programming language before, especially
      when combined with flexible but general syntax, such as infix calls.
    </p>
  </body>
</html>
