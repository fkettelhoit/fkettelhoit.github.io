<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Reasonable Macros</title>
    <link rel="stylesheet" href="../styles/style.css" />
  </head>
  <body>
    <p>
      <a href="../index.html">Notes</a><br /><time datetime="2025-04-20"
        >2025/04/20</time
      >
    </p>
    <h1>Reasonable Macros</h1>
    <p>
      Over the past couple of weeks I've been experimenting with a restricted
      form of metaprogramming that supports user-defined control structures and
      <a
        href="https://people.csail.mit.edu/gregs/ll1-discuss-archive-html/msg01539.html"
        >binding constructs</a
      >
      such as pattern matching and let statements without the need for full
      Lisp-like macros. By restricting macros slightly, it is possible to reason
      about them statically, without giving up most of the power that full
      macros provide.
    </p>
    <p>
      The key idea is to make <em>bindings explicit.</em> This basically means
      explicitly distinguishing between <em>using</em> a variable and
      <em>binding</em> a value to it. Whenever a variable x is used, it is
      simply written as x, but when a variable is meant to be bound to a value
      (which can happen in a lambda expression, in a let statement, as part of
      pattern matching or anything else we could come up with) it is prefixed
      with a single quote and written as 'x.
    </p>
    <pre><code>f(x)           // the variables f and x are used, no quote necessary
'x => { g(x) } // the lambda binds the variable x in the body g(x)</code></pre>
    <h1>Privileged Syntax or Full Macros?</h1>
    <p>
      The alternatives to explicitly distinguishing uses and bindings are to
      either privilege some control structures or binding constructs as core
      syntax that cannot be redefined (which is what most languages do), so that
      for example variables always need to be declared using “=”, or to add
      support for macros, which can operate on the
      <em>syntactic structure</em> of a program <em>before</em> variables are
      resolved, so that a macro can decide whether to treat the variable x in
      f(x) as a variable (and resolve it) or just a symbol (and bind it).
    </p>
    <p>
      The problem with macros is that while they are powerful, they make it hard
      (for humans and compilers) to reason about a program before a macro is
      expanded: Just seeing an expression such as f(2 + 2) in the source code
      does not guarantee that it is equivalent to f(4), because f could be a
      macro and thus treat 2 + 2 differently from 4. By exposing
      <em>all of the syntactic structure</em> of a program, macros have to be
      used sparingly and/or expanded before it is possible reason about
      equivalent expressions.
    </p>
    <p>
      This observation dates back at least to papers by
      <a
        href="https://www.sciencedirect.com/science/article/pii/0167642393900049/pdf?md5=ea488cdb5aac4a6277500017c5a105ba&pid=1-s2.0-0167642393900049-main.pdf"
        >Mitchell</a
      >
      and
      <a
        href="https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=dc9cdd51c6e02c45ab267c9973e5c4af9fb11e44"
        >Wand</a
      >
      in the context of Lisp <em>fexprs</em> instead of <em>macros.</em> Both
      fexprs and macros operate on unevaluated operands (instead of evaluated
      arguments), they can thus observe the <em>syntactic structure</em> of
      their operands, but they differ in what and when they return: Fexprs
      return a <em>value</em> and can potentially run at
      <em>run time,</em> whereas macros produce an output expression, a syntax
      tree that is inserted into the program at <em>compile time.</em> While it
      might technically be true that it is possible to reason about equivalent
      expressions <em>after macro expansion</em> (which is harder for fexprs
      that might be evaluated at runtime), let's instead look at a restricted
      form of macros, using explicit bindings, that supports equational
      reasoning without the need to expand any macros.
    </p>
    <h1>From Fexprs to Reasonable Macros</h1>
    <p>
      Let's take a step back and first look at how fexprs work in John Shutt's
      <a
        href="https://web.cs.wpi.edu/~jshutt/dissertation/etd-090110-124904-Shutt-Dissertation.pdf"
        >Kernel language</a
      >, then restrict them by using explicit bindings.
    </p>
    <p>
      In a nutshell, fexprs are functions that do not evaluate their arguments
      by default. An argument such as “2 + 2” remains an abstract syntax tree
      until it is <em>explicitly evaluated</em> in an environment. An fexpr is
      free to never evaluate any of its arguments or it can evaluate all of its
      arguments before use, in which case it acts like a regular function.
      Kernel calls fexprs that do not evaluate their arguments
      <em>operatives</em>, while functions that do evaluate their arguments are
      called <em>applicatives</em>. An operative is more fundamental than an
      applicative, since an applicative can be built by wrapping an operative in
      such a way that arguments are evaluated and then passed to the operative.
    </p>
    <p>
      One thing to point out is that operatives do not evaluate
      <em>anything</em> by default, all evaluation has to happen explicitly.
      This is why it is impossible for a compiler to replace an expression like
      f(2 + 2) with f(4) until it knows whether f is an operative or an
      applicative. In Kernel, this is by design, because operatives are meant to
      be a <em>semantic abstraction</em>, which does not rely on a phase
      separatiion between run time and compile time. In contrast, macros are a
      <em>syntactic abstraction</em>, because they are expanded exclusively at
      compile time. Macros thus rely on the phase separation between run time
      and compile time, but they do not place other restrictions on how
      evaluation takes place.
    </p>
    <p>
      By introducing explicit bindings of the form 'x, which distinguish between
      variables-to-be-used and variables-to-be-bound, Kernel-style operatives
      can be restricted in such a way that they become a syntactic abstraction
      (like macros), but can run either at run time or compile time (like
      Kernel-style operatives) and can be reasoned about statically without any
      evaluation or macro expansion (unlike Kernel-style operatives or Lisp
      macros).
    </p>
    <p>
      The idea is simple: Any expression is evaluated by default (just like in
      regular functions) unless it contains a quoted variable such as 'x, in
      which case it remains unevaluated and its syntactic structure can be
      observed (just like in Kernel operatives).
    </p>
    <pre><code>f(2 + 2)     // no explicit bindings, can be replaced with f(4)
f('x)        // 'x is a binding, so x remains unevaluated
f('x, y + z) // y + z will be evaluated, but x remains unevaluated</code></pre>
    <p>
      It is thus <em>syntactically</em> clear when and where evaluation happens:
      A compiler can safely optimize any expression that does not contain
      explicit bindings.
    </p>
    <p>
      To resolve unquoted variables statically, the scope of variables must be
      statically tracked. The goal of explicit bindings is to make it possible
      to define and re-define binding constructs, but there needs to be some
      built-in syntax for block scope so that it is clear when and where
      bindings are introduced. This can be done using special syntax for lambda
      bindings or by
      <a href="./003-custom-binding-constructs-without-macros.html"
        >statically associating explicit bindings</a
      >
      with blocks where they are used, so that in f('x, { x + y }) the block { x
      + y } is statically guaranteed to be a lambda abstraction with one
      variable x (because 'x appears as an argument to f).
    </p>
    <h1>Reasonable Macros as Syntactic Sugar</h1>
    <p>
      To be clear, making bindings explicit and syntactic marks a
      <em>loss of power</em> compared to Kernel-style fexprs, which is made even
      more evident by the fact that a lambda abstraction in Kernel can be built
      out of an operative, whereas some form special of block syntax is
      necessary with explicit bindings. This is by design, because these
      syntactic restrictions make it possible to reason about macro-like
      metaprogramming statically. This makes it possible to implement explicit
      bindings purely syntactically and translate everything into a normal
      call-by-value lambda calculus.
    </p>
    <p>
      Here is a sketch of how this looks like: As mentioned, there needs to be
      some kind of lambda or block syntax which gets translated into normal
      lambda abstractions during parsing. More interesting is how to translate
      other expressions in such a way that they can be evaluated in a
      call-by-value lambda calculus while retaining the ability to observe their
      syntactic structure in macros. To do this, all expressions are translated
      as follows:
    </p>
    <ul>
      <li>
        Expressions that do not contain any explicit bindings are simply
        evaluated normally and then marked as values. An expression such as 2 +
        2 would be translated to Value(4). This guarantees that the names of
        variables that are <em>used</em> are never observable, because a
        variable is resolved and marked as a value.
      </li>
      <li>
        Explicit bindings are treated as strings and marked as bindings, so that
        'x is translated to Binding("x"). This ensures that the names of
        explicit bindings are observable. Since variables are resolved and
        marked as values, any binding that does not appear directly as a
        function argument but rather “by proxy” is wrapped as a value. For
        example, assuming that x = 'y, the expression x would be translated to
        Value(Binding("y")).
      </li>
      <li>
        Expressions that contain explicit bindings as their subexpressions are
        more interesting: One option is to simply evaluate these expressions, so
        that f('x) is a function applied to the value Binding("x"). This is
        closest to the spirit of fexprs and Kernel-style operatives, as
        described above. But another option is to keep functions applied to
        bindings unevaluated until they are applied to a lambda or block,
        because lambdas/blocks are where bindings are used. To allow this,
        expressions containing bindings as subexpression are recursively
        translated and marked as compound expressions that contain bindings, so
        that (assuming the variable f can be resolved to some value g) the
        expression f(2 + 2, 'x) is translated to Compound(Value(g), Value(4),
        Binding("x")).
      </li>
    </ul>
    <p>
      This is merely a rough sketch and I need to experiment more with the
      resulting language, but the direction seems interesting. Making bindings
      explicit is only a slight departure from traditional syntax, but might
      unlock 80% of the common uses of macros without introducing a full-blown
      macro system.
    </p>
  </body>
</html>
